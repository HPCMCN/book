# 1. 进程

## 1.1 进程简介

### 1.1.1 0号进程

操作系统在启动的瞬间先创建0号进程, 0进程来调度其他进程,并创建1号进程间接或者直接创建其他进程

### 1.1.2 进程回收

主进程执行完成后, 等待子进程的结束, 并回收内存, 如果出现异常的话, 则会产生僵尸进程或孤儿进程

#### 1.1.2.1 僵尸进程

- 子进程比父进程先终止, 但是父进程是死循环, 无法回收子进程创建的资源空间. 使用ps查询状态是Z. 
   ![img](.image/31-%E8%BF%9B%E7%A8%8B/732a214e-67a6-4db8-a708-8a0c74417121.png)
- 如果父进程会终止, 则父进程(或者0号进程)会把子进程的占用的资源空间释放掉

代码实现

 

```
from multiprocessing import Process
def foo():
    print(222)
if __name__ == '__main__':
    p = Process(target=foo)
    p.start()
    while True:
        import time
        print(111)
        time.sleep(1)
```

#### 1.1.2.2 孤儿进程

- 主进程结束, 子进程给系统init 0号进程进程管理并结束回收内存空间 
   ![img](.image/31-%E8%BF%9B%E7%A8%8B/d17d1f7b-4248-41c3-a995-de322ad7b13a.png)
- 在未回收这段时间类, 这个进程叫做僵尸进程

代码实现

 

```
import os
import time
from multiprocessing import Process


def foo():
    for i in range(20):
        print(222)
        time.sleep(1)


if __name__ == '__main__':
    p = Process(target=foo)
    p.start()
    print(111)
    os._exit(0)
```

### 1.3.1 资源读写

多进程间的资源是不共享的, 但是子进程与父进程之间的资源关系如下

- 读取时  共享
- 修改是 重新开辟内存空间, 深copy数据到开辟的空间中, 形成隔离

这种处理方式叫做写时copy

## 1.2 进程创建

### 1.2.1 fork

最底层的进程创建, 不过需要考虑的因素比较多, 一般不要用. 

#### 1.2.1.1 入口函数

* 由于windows中不存在`fork`函数, 无法自动创建进程, 只能重载模块来开辟进程.
* 所以为了避免模块重载时, 陷入死循环, 必须要做一个判断来跳出循环, 不然代码每次走到创建进程的位置就要重载模块来创建进程. 此时入口函数就诞生了.

* Python中`__name__`, 在主动运行时输出为`__main__`, 被动调用时输出为当前模块名称, 所以可以用此函数来判断是模块重载还是主动运行.

**所以** 为了避免此类现象发生, 最好左右代码的执行都在`if __name__ == "__main__"`中执行

```python
import time
from multiprocessing import Process

def foo():
    print(222)
    time.sleep(1)

print("It will be reload: ", 111)
if __name__ == '__main__':
    p = Process(target=foo)
    p.start()
    print(333)
```

输出

```python
hpcm@D***U:/mnt/e/project/py37$ python3 test.py
It will be reload: 111
333
222
hpcm@D***U:/mnt/e/project/py37$ 
```

#### 1.2.1.2 fork进程

* **fork**

创建进程,. 并返回`int`类型,  当`int > 0`表示为主进程,  `int==0`表示为子进程

```python
def fork():
return int
```

**示例**

```python
import os
import time
def demo():
    print("[INFO] do something by process {}".format(os.getpid()))
    print("[INFO] this process parent pid is {}".format(os.getppid()))

if __name__ == "__main__":
    process = os.fork()
    print(process)
    if process == 0:
        demo()
    print("main process {} is over".format(os.getpid()))
    time.sleep(1)
```

输出

```python
26272
main process 26192 is over
0
[INFO] do something by process 26272
[INFO] this process parent pid is 26271
main process 26271 is over
```

### 1.2.2 Process

参见`multiprocessing`模块, 示例如下

```python
import time
from multiprocessing import Process, connection

def foo(a, *, b):
    import random
    s = random.randint(0, 2)
    time.sleep(s)
    print(a, b, s)

if __name__ == '__main__':
    file_nums = []
    p_list = []
    for i in range(4):
        p = Process(target=foo, args=(1,), kwargs={"b": 2})
        p.start()
        p_list.append(p)
        file_nums.append(p.sentinel)
    # connection.wait(file_nums)
    [p.join() for p in p_list]
    print(2222)
```

输出

```python
1 2 0
1 2 1
1 2 1
1 2 2
2222
```

# 2. 进程池

## 2.1 Pool

参见`multiprocess.Pool`模块, 示例如下

```python
import time
from multiprocessing import Pool, cpu_count


def demo(a):
    print("[INFO] get {}".format("www.b***u.com"))
    time.sleep(1)
    print("[INFO] complete {}".format("www.b***u.com"))
    return a


if __name__ == '__main__':
    pool = Pool(cpu_count())
    # task_list = []
    # for i in range(20):
    # task = pool.apply_async(func=demo, args=[1, 3, 5], callback=None)
    # task_list.append(task)
    # [task.wait() for task in task_list]
    # for complete in [task.get() for task in task_list]:
    # print(complete)
    params = [i for i in range(10)]
    # tasks = pool.map(demo, params)
    tasks = pool.map_async(demo, params)
    # tasks = pool.imap_unordered(demo, params)
    # tasks = pool.imap(demo, params)
    print(tasks.wait())
    print(tasks.get())
    # for task in tasks:
    #     print(task)
    # pool.close()
    # task_list.wait()
    print()
    # pool.close()
```

输出

```python
[INFO] get www.b***u.com
[INFO] get www.b***u.com
[INFO] get www.b***u.com
[INFO] complete www.b***u.com
[INFO] complete www.b***u.com
[INFO] complete www.b***u.com
None
[0, 1, 2]
```

## 2.2 ProcessPoolExecutor

参见`concurrent.futures.ProcessPoolExecutor`, 示例如下

```python
import time
import random
from concurrent.futures import ProcessPoolExecutor, as_completed, wait, FIRST_COMPLETED
# noinspection PyUnresolvedReferences
from concurrent.futures import Future


def func(t):
    time.sleep(t)
    print("This time is {}".format(t))
    return t

if __name__ == "__main__":
    # 设置线程启用个数
    cor = ProcessPoolExecutor(3)
    # 执行任务
    # task1 = cor.submit(func, *[1])
    # 实时获取每个任务的返回值
    task_list = [cor.submit(func, random.randint(1, 4)) for i in range(5)]
    # 主进程等待, 直到一个任务执行完成
    wait(task_list, return_when=FIRST_COMPLETED)
    print("__Main__")
    for task in as_completed(task_list):
        data = task.result()
        print(data)

    # 此方法获取到的结果不是实时的
    # submit_list = [random.randint(1, 4) for _ in range(20)]
    # for data in cor.map(func, submit_list):
    #     print(data)
    # print(task1.done())
    # # 获取任务结果
    # print(task1.result())
    # # 任务取消必须是放入队列中, 但是未执行的任务
    # print(task1.cancel())
```

输出

```python
This time is 2
__Main__
2
This time is 1
1
This time is 4
4
This time is 4
4
This time is 4
4
```

# 3. 进程通讯

进程通讯的方式有很多种: 队列, 管道等等.

队列: 

* 让进程间实现通讯
* 无需限制进程开启数量, 保证内存稳定

## 3.1 Queue

参见`multiprocessing.Queue`, 示例如下

**示例**

```python
# 适用于: 进程, 线程|线程池
import time
from multiprocessing import Process, Queue, cpu_count

def demo1(q):
    i = 0
    while True:
        q.put(i)
        if i == 20:
            break
        i += 1

def demo2(q):
    while True:
        print(q.get())
        time.sleep(1)
        if q.empty() is True:
            break
    print("over")

if __name__ == "__main__":
    q = Queue(cpu_count())
    p1 = Process(target=demo1, args=(q,))
    p2 = Process(target=demo2, args=(q,))
    p3 = Process(target=demo2, args=(q,))
    p1.start()
    p2.start()
    p3.start()
    p1.join()
    p2.join()
    p3.join()
```

## 3.2 Pipe

支持两个进程间进行通讯

**示例**

```python
# 使用于: 两个进程间通讯
from multiprocessing import Pipe, Process
def send(pipe, datas):
    for data in datas:
        pipe.send(data)

def rev(pipe):
    while True:
        data = pipe.recv()
        print(data)
        if not pipe.poll():
            break

if __name__ == "__main__":
    pipe_rec, pipe_send = Pipe()
    p1 = Process(target=send, args=[pipe_send, range(20)])
    p2 = Process(target=rev, args=[pipe_rec])
    p1.start()
    p2.start()
    p1.join()
    p2.join()
```

## 3.2 Manager

参见`multiprocessing.Manager `

基于`pipe`通信构建的进程通讯

`Manager`支持如下类型在进程间进行通讯.

| 类型               | 说明 |
| ------------------ | ---- |
| `Barrier`          |      |
| `BoundedSemaphore` |      |
| `Condition`        |      |
| `Event`            |      |
| `Lock`             |      |
| `Namespace`        |      |
| `Queue`            |      |
| `Rlock`            |      |
| `Semaphore`        |      |
| `Array`            |      |
| `Value`            |      |
| `dict`             |      |
| `list`             |      |

### 3.1.1 **Queue**

```python
# 进程池只能用这个方法
# 适用于: 进程|进程池, 线程|线程池
import time
from multiprocessing import Pool
from multiprocessing import Manager

def demo1(q):
    i = 0
    while True:
        q.put(i)
        if i == 20:
            break
        i += 1

def demo2(q):
    while True:
        print(q.get())
        time.sleep(1)
        if q.empty() is True:
            break
    print("over")

if __name__ == "__main__":
    pool = Pool(10)
    q = Manager().Queue(2)
    pool.apply_async(demo1, args=(q,))
    pool.apply_async(demo2, args=(q,))
    pool.apply_async(demo2, args=(q,))
    pool.close()
    pool.join()
```

### 3.1.2 dict

```python
from multiprocessing import Process, Manager
def share_put(dict_share):
    for i in range(10):
        dict_share[i] = i

def share_get(dict_share):
    print(dict_share)

if __name__ == '__main__':
    share_dict = Manager().dict()
    p1 = Process(target=share_put, args=[share_dict])
    p1.start()
    p2 = Process(target=share_get, args=[share_dict])
    p2.start()
    p1.join()
    p2.join()
```

