# Ollama + WebUI + SD

* ollama安装

  官方网址: https://ollama.com/, 下载直接安装即可

  环境变量说明:

  * OLLAMA_MODELS

    模型下载路径, win=`%userprofile%\.ollama\models`

  * OLLAMA_HOST

    ollama服务启动监听地址, default=localhost

* 安装webui

  ```shell
  docker run -d -p 8001:8080 -v ./open-webui:/app/backend/data -e OLLAMA_BASE_URL=http://<ollama_ip>:11434 --name ollama-webui --restart always ghcr.io/open-webui/open-webui:main
  ```

  **注意**:

  ​	正常来说启动会出现异常, 国服理论上都会出现异常, 下载模型的地址会连接失败, 我这里只是使用ui的web界面, 不用下载模型, 目的是web页面和模型服务可以分离部署.所以这里需要进行一下操作

  * 将代码copy出来进行调整

    ```shell
    docker cp ollama-webui:/app/backend ./
    ```

  * 修改代码如下

    ```python
    # vim backend/apps/rag/main.py
    
    #注释一下代码, 大概92行左右
    #app.state.sentence_transformer_ef = (
    #    embedding_functions.SentenceTransformerEmbeddingFunction(
    #       model_name=app.state.RAG_EMBEDDING_MODEL,
    #        device=RAG_EMBEDDING_MODEL_DEVICE_TYPE,
    #    )
    #)
    ```

  * 删除原来的代码

    ```shell
    docker exec -it ollama-webui /bin/bash -c 'ls /app/backend/apps/rag/main.py'
    ```

  * 替换进去

    ```shell
    docker cp ./backend/apps/rag/main.py ollama-webui:/app/backend/apps/rag
    ```

  * 检查服务

    ```shell
    curl 127.0.0.1:8001
    ```

* web ui接入ollama

  web ui接入到ollama即可使用gpt功能, 比如正常的对话

  ![image-20240410103606617](.image/01-%E5%AE%89%E8%A3%85/image-20240410103606617.png)

* Stable Diffusion

  保证原有的Stable Diffusion能正常运行, 然后进行如下操作

  * 修改`webui.py`文件

    ```shell
    # 大概73行
    server_name = "0.0.0.0"
    ```

  保存后, 重新启动

* web ui接入Stable Diffusion

  ![image-20240410095726083](.image/01-%E5%AE%89%E8%A3%85/image-20240410095726083.png)

* 寻找关键词模型

  进入网站: ollama.com 搜索: Stable Diffusion

  找到生成关键词的模型, 进入到终端执行:

  ```shell
  ollama run <model>
  ```

* 到open webui中选择对应的模型开始对话

  注意利用模型提供的提示词, 生成tu'pian

  ![image-20240410100017564](.image/01-%E5%AE%89%E8%A3%85/image-20240410100017564.png)

